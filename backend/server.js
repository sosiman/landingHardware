// server.js - Backend API para chat con OpenAI
import express from 'express';
import cors from 'cors';
import rateLimit from 'express-rate-limit';
import OpenAI from 'openai';

const app = express();
const PORT = process.env.PORT || 3001;

// Configurar OpenAI
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

// Logs de configuraciÃ³n al iniciar
console.log('='.repeat(60));
console.log('ğŸš€ ConfiguraciÃ³n de OpenAI API');
console.log('='.repeat(60));
console.log('âœ“ API Key configurada:', process.env.OPENAI_API_KEY ? `${process.env.OPENAI_API_KEY.slice(0, 10)}...` : 'âŒ NO CONFIGURADA');
console.log('âœ“ Modelo General (OPENAI_MODEL):', process.env.OPENAI_MODEL || 'gpt-4o (default)');
console.log('âœ“ Modelo Codex (CODEX_MODEL):', process.env.CODEX_MODEL || 'gpt-4o (default)');
console.log('âœ“ Modelo de ImÃ¡genes (OPENAI_IMAGE_MODEL):', process.env.OPENAI_IMAGE_MODEL || 'dall-e-3 (default)');
console.log('='.repeat(60));

// Middleware
app.use(express.json());

// CORS - permite peticiones desde tu dominio
app.use(cors({
  origin: [
    'https://lockthard.es',
    'https://www.lockthard.es',
    'http://localhost:5173', // Para desarrollo local
    'http://localhost:3000'
  ],
  credentials: true
}));

// Rate limiting - mÃ¡ximo 20 peticiones por minuto
const limiter = rateLimit({
  windowMs: 60 * 1000, // 1 minuto
  max: 20,
  message: { error: 'Demasiadas peticiones, intenta de nuevo en un minuto' }
});

app.use('/api/', limiter);

// Health check
app.get('/health', (req, res) => {
  res.json({ status: 'ok', timestamp: new Date().toISOString() });
});

// Endpoint de diagnÃ³stico para verificar configuraciÃ³n
app.get('/api/config', (req, res) => {
  res.json({
    status: 'ok',
    openai: {
      apiKeyConfigured: !!process.env.OPENAI_API_KEY,
      apiKeyPrefix: process.env.OPENAI_API_KEY ? process.env.OPENAI_API_KEY.slice(0, 10) + '...' : 'NOT_SET',
      models: {
        general: process.env.OPENAI_MODEL || 'gpt-4o (default)',
        codex: process.env.CODEX_MODEL || 'gpt-4o (default)',
        image: process.env.OPENAI_IMAGE_MODEL || 'dall-e-3 (default)'
      }
    },
    server: {
      port: PORT,
      nodeEnv: process.env.NODE_ENV || 'development'
    },
    timestamp: new Date().toISOString()
  });
});

// Endpoint principal del chat
app.post('/api/chat', async (req, res) => {
  try {
    const { message, conversationHistory = [] } = req.body;

    // ValidaciÃ³n
    if (!message || typeof message !== 'string') {
      return res.status(400).json({
        error: 'El mensaje es requerido y debe ser un string'
      });
    }

    if (message.length > 2000) {
      return res.status(400).json({
        error: 'El mensaje es demasiado largo (mÃ¡ximo 2000 caracteres)'
      });
    }

    // Preparar mensajes para OpenAI
    const messages = [
      {
        role: 'system',
        content: 'Eres un asistente Ãºtil y amigable de Lockthard. Responde de forma concisa y profesional.'
      },
      ...conversationHistory.slice(-10), // Solo Ãºltimos 10 mensajes
      {
        role: 'user',
        content: message
      }
    ];

    // Llamar a OpenAI
    const completion = await openai.chat.completions.create({
      model: process.env.OPENAI_MODEL || 'gpt-4o',
      messages: messages,
      max_tokens: 500,
      temperature: 0.7
    });

    const reply = completion.choices[0].message.content;

    res.json({
      reply,
      usage: {
        prompt_tokens: completion.usage.prompt_tokens,
        completion_tokens: completion.usage.completion_tokens,
        total_tokens: completion.usage.total_tokens
      }
    });

  } catch (error) {
    console.error('Error en /api/chat:', error.message);

    if (error.code === 'insufficient_quota') {
      return res.status(402).json({
        error: 'Sin crÃ©ditos de OpenAI disponibles'
      });
    }

    res.status(500).json({
      error: 'Error al procesar tu mensaje. Intenta de nuevo.'
    });
  }
});

// Endpoint especÃ­fico para chat con Codex
app.post('/api/chat/codex', async (req, res) => {
  console.log('ğŸ“¨ Nueva peticiÃ³n a /api/chat/codex');
  console.log('ğŸ”§ Modelo configurado:', process.env.CODEX_MODEL || 'gpt-4o (default)');

  try {
    const { message, conversationHistory = [] } = req.body;

    // ValidaciÃ³n
    if (!message || typeof message !== 'string') {
      return res.status(400).json({
        error: 'El mensaje es requerido y debe ser un string'
      });
    }

    if (message.length > 2000) {
      return res.status(400).json({
        error: 'El mensaje es demasiado largo (mÃ¡ximo 2000 caracteres)'
      });
    }

    // Preparar mensajes para OpenAI con contexto de desarrollo
    const messages = [
      {
        role: 'system',
        content: 'Eres un asistente experto en desarrollo de software. Ayudas con cÃ³digo, arquitectura, debugging, mejores prÃ¡cticas y soluciones tÃ©cnicas. Responde de forma concisa, tÃ©cnica y profesional. Proporciona ejemplos de cÃ³digo cuando sea apropiado.'
      },
      ...conversationHistory.slice(-10), // Solo Ãºltimos 10 mensajes
      {
        role: 'user',
        content: message
      }
    ];

    // Llamar a OpenAI con GPT-4o
    const modelToUse = process.env.CODEX_MODEL || 'gpt-4o';
    console.log('ğŸ¤– Llamando a OpenAI con modelo:', modelToUse);

    const completion = await openai.chat.completions.create({
      model: modelToUse,
      messages: messages,
      max_tokens: 1000,
      temperature: 0.5
    });

    console.log('âœ… Respuesta recibida exitosamente de OpenAI');

    const reply = completion.choices[0].message.content;

    res.json({
      reply,
      usage: {
        prompt_tokens: completion.usage.prompt_tokens,
        completion_tokens: completion.usage.completion_tokens,
        total_tokens: completion.usage.total_tokens
      }
    });

  } catch (error) {
    console.error('âŒ Error en /api/chat/codex:');
    console.error('â”'.repeat(60));
    console.error('Mensaje:', error.message);
    console.error('CÃ³digo:', error.code);
    console.error('Status:', error.status);
    console.error('Tipo:', error.type);
    console.error('Modelo intentado:', process.env.CODEX_MODEL || 'gpt-4o');
    console.error('Error completo:', JSON.stringify(error, null, 2));
    console.error('â”'.repeat(60));

    // Error de modelo no encontrado
    if (error.code === 'model_not_found' || error.status === 404) {
      return res.status(404).json({
        error: 'Modelo no disponible',
        details: `El modelo "${process.env.CODEX_MODEL || 'gpt-4o'}" no estÃ¡ disponible en tu cuenta de OpenAI. Verifica tu suscripciÃ³n o usa un modelo diferente.`,
        model: process.env.CODEX_MODEL || 'gpt-4o'
      });
    }

    // Error de cuota insuficiente
    if (error.code === 'insufficient_quota') {
      return res.status(402).json({
        error: 'Sin crÃ©ditos de OpenAI disponibles',
        details: 'Tu cuenta de OpenAI no tiene crÃ©ditos suficientes'
      });
    }

    // Error de permisos
    if (error.status === 401 || error.code === 'invalid_api_key') {
      return res.status(401).json({
        error: 'API Key invÃ¡lida',
        details: 'La API Key de OpenAI no es vÃ¡lida o ha expirado'
      });
    }

    // Error de rate limit
    if (error.code === 'rate_limit_exceeded' || error.status === 429) {
      return res.status(429).json({
        error: 'LÃ­mite de solicitudes excedido',
        details: 'Has excedido el lÃ­mite de solicitudes. Intenta de nuevo en unos momentos.'
      });
    }

    // Error genÃ©rico
    res.status(500).json({
      error: 'Error al procesar tu mensaje',
      details: error.message || 'Error desconocido. Revisa los logs del servidor.',
      model: process.env.CODEX_MODEL || 'gpt-4o'
    });
  }
});

// Endpoint para generar imÃ¡genes con DALL-E 3
app.post('/api/generate-image', async (req, res) => {
  try {
    const { prompt } = req.body;

    // ValidaciÃ³n
    if (!prompt || typeof prompt !== 'string') {
      return res.status(400).json({
        error: 'El prompt es requerido y debe ser un string'
      });
    }

    if (prompt.length > 4000) {
      return res.status(400).json({
        error: 'El prompt es demasiado largo (mÃ¡ximo 4000 caracteres)'
      });
    }

    // Llamar a DALL-E 3
    const imageModel = process.env.OPENAI_IMAGE_MODEL || 'dall-e-3';
    const response = await openai.images.generate({
      model: imageModel,
      prompt: prompt,
      n: 1,
      size: '1024x1024',
      quality: 'standard',
      response_format: 'url'
    });

    const imageUrl = response.data[0].url;
    const revisedPrompt = response.data[0].revised_prompt;

    res.json({
      imageUrl,
      revisedPrompt,
      model: imageModel
    });

  } catch (error) {
    console.error('Error en /api/generate-image:', error.message);

    if (error.code === 'insufficient_quota') {
      return res.status(402).json({
        error: 'Sin crÃ©ditos de OpenAI disponibles'
      });
    }

    if (error.code === 'content_policy_violation') {
      return res.status(400).json({
        error: 'El contenido del prompt viola las polÃ­ticas de OpenAI'
      });
    }

    res.status(500).json({
      error: 'Error al generar la imagen. Intenta de nuevo.'
    });
  }
});

// Manejo de rutas no encontradas
app.use((req, res) => {
  res.status(404).json({ error: 'Ruta no encontrada' });
});

// Iniciar servidor
app.listen(PORT, '0.0.0.0', () => {
  console.log(`ğŸš€ Backend API corriendo en puerto ${PORT}`);
  console.log(`ğŸ“ Health check: http://localhost:${PORT}/health`);
});